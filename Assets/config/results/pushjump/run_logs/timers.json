{
    "name": "root",
    "gauges": {
        "EnemyShooter.Policy.Entropy.mean": {
            "value": 1.4910982847213745,
            "min": 1.4420478343963623,
            "max": 1.4913194179534912,
            "count": 2328
        },
        "EnemyShooter.Policy.Entropy.sum": {
            "value": 1526.8846435546875,
            "min": 738.3284912109375,
            "max": 1527.111083984375,
            "count": 2328
        },
        "EnemyShooter.Step.mean": {
            "value": 2483968.0,
            "min": 156992.0,
            "max": 2483968.0,
            "count": 2328
        },
        "EnemyShooter.Step.sum": {
            "value": 2483968.0,
            "min": 156992.0,
            "max": 2483968.0,
            "count": 2328
        },
        "EnemyShooter.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.003981497138738632,
            "min": 0.00043355327215977013,
            "max": 2.2424635887145996,
            "count": 2328
        },
        "EnemyShooter.Policy.ExtrinsicValueEstimate.sum": {
            "value": 0.06370395421981812,
            "min": 0.006503298878669739,
            "max": 35.879417419433594,
            "count": 2328
        },
        "EnemyShooter.Policy.CuriosityValueEstimate.mean": {
            "value": 0.14167653024196625,
            "min": -0.01020139828324318,
            "max": 5.496249675750732,
            "count": 2328
        },
        "EnemyShooter.Policy.CuriosityValueEstimate.sum": {
            "value": 2.26682448387146,
            "min": -0.153020977973938,
            "max": 84.20790100097656,
            "count": 2328
        },
        "EnemyShooter.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 2328
        },
        "EnemyShooter.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 2328
        },
        "PushAgent2D.Policy.Entropy.mean": {
            "value": 0.7385470271110535,
            "min": 0.7259157299995422,
            "max": 1.7212377786636353,
            "count": 582
        },
        "PushAgent2D.Policy.Entropy.sum": {
            "value": 732.638671875,
            "min": 413.5155029296875,
            "max": 1707.4678955078125,
            "count": 582
        },
        "PushAgent2D.Step.mean": {
            "value": 737974.0,
            "min": 156988.0,
            "max": 737974.0,
            "count": 582
        },
        "PushAgent2D.Step.sum": {
            "value": 737974.0,
            "min": 156988.0,
            "max": 737974.0,
            "count": 582
        },
        "PushAgent2D.Policy.ExtrinsicValueEstimate.mean": {
            "value": -6.625072002410889,
            "min": -20.09725570678711,
            "max": -1.7419523000717163,
            "count": 582
        },
        "PushAgent2D.Policy.ExtrinsicValueEstimate.sum": {
            "value": -205.37722778320312,
            "min": -641.6571044921875,
            "max": -54.00052261352539,
            "count": 582
        },
        "PushAgent2D.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 582
        },
        "PushAgent2D.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 582
        },
        "AgentController2D.Policy.Entropy.mean": {
            "value": 0.17078474164009094,
            "min": 0.05118463188409805,
            "max": 1.0986055135726929,
            "count": 582
        },
        "AgentController2D.Policy.Entropy.sum": {
            "value": 174.88357543945312,
            "min": 49.137245178222656,
            "max": 1124.968994140625,
            "count": 582
        },
        "AgentController2D.Step.mean": {
            "value": 737984.0,
            "min": 156992.0,
            "max": 737984.0,
            "count": 582
        },
        "AgentController2D.Step.sum": {
            "value": 737984.0,
            "min": 156992.0,
            "max": 737984.0,
            "count": 582
        },
        "AgentController2D.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.5128580331802368,
            "min": -1.0024863481521606,
            "max": -0.40663260221481323,
            "count": 582
        },
        "AgentController2D.Policy.ExtrinsicValueEstimate.sum": {
            "value": -8.205728530883789,
            "min": -16.03978157043457,
            "max": -2.090259552001953,
            "count": 582
        },
        "AgentController2D.Policy.CuriosityValueEstimate.mean": {
            "value": 0.05320308357477188,
            "min": -0.10690773278474808,
            "max": 2.3646037578582764,
            "count": 582
        },
        "AgentController2D.Policy.CuriosityValueEstimate.sum": {
            "value": 0.8512493371963501,
            "min": -1.7105237245559692,
            "max": 14.593670845031738,
            "count": 582
        },
        "AgentController2D.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 582
        },
        "AgentController2D.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 582
        },
        "PushAgent2D.Environment.EpisodeLength.mean": {
            "value": 2828.0,
            "min": 1536.0,
            "max": 117952.0,
            "count": 17
        },
        "PushAgent2D.Environment.EpisodeLength.sum": {
            "value": 2828.0,
            "min": 1536.0,
            "max": 117952.0,
            "count": 17
        },
        "PushAgent2D.Environment.CumulativeReward.mean": {
            "value": -199.30487920716405,
            "min": -8687.003874655813,
            "max": -99.97037820518017,
            "count": 17
        },
        "PushAgent2D.Environment.CumulativeReward.sum": {
            "value": -199.30487920716405,
            "min": -8687.003874655813,
            "max": -99.97037820518017,
            "count": 17
        },
        "PushAgent2D.Policy.ExtrinsicReward.mean": {
            "value": -199.30487920716405,
            "min": -8687.003874655813,
            "max": -99.97037820518017,
            "count": 17
        },
        "PushAgent2D.Policy.ExtrinsicReward.sum": {
            "value": -199.30487920716405,
            "min": -8687.003874655813,
            "max": -99.97037820518017,
            "count": 17
        },
        "EnemyShooter.Losses.PolicyLoss.mean": {
            "value": 0.04844903616489183,
            "min": 0.043817517449828654,
            "max": 0.052409442358575066,
            "count": 20
        },
        "EnemyShooter.Losses.PolicyLoss.sum": {
            "value": 0.04844903616489183,
            "min": 0.043817517449828654,
            "max": 0.052409442358575066,
            "count": 20
        },
        "EnemyShooter.Losses.ValueLoss.mean": {
            "value": 5.815723460677054e-05,
            "min": 4.9325890562251953e-05,
            "max": 0.11966081494253368,
            "count": 20
        },
        "EnemyShooter.Losses.ValueLoss.sum": {
            "value": 5.815723460677054e-05,
            "min": 4.9325890562251953e-05,
            "max": 0.11966081494253368,
            "count": 20
        },
        "EnemyShooter.Policy.LearningRate.mean": {
            "value": 4.736098105599991e-06,
            "min": 4.736098105599991e-06,
            "max": 0.0002005120197952001,
            "count": 20
        },
        "EnemyShooter.Policy.LearningRate.sum": {
            "value": 4.736098105599991e-06,
            "min": 4.736098105599991e-06,
            "max": 0.0002005120197952001,
            "count": 20
        },
        "EnemyShooter.Policy.Epsilon.mean": {
            "value": 0.10189439999999995,
            "min": 0.10189439999999995,
            "max": 0.18020479999999997,
            "count": 20
        },
        "EnemyShooter.Policy.Epsilon.sum": {
            "value": 0.10189439999999995,
            "min": 0.10189439999999995,
            "max": 0.18020479999999997,
            "count": 20
        },
        "EnemyShooter.Policy.Beta.mean": {
            "value": 0.00019925055999999968,
            "min": 0.00019925055999999968,
            "max": 0.008022459519999999,
            "count": 20
        },
        "EnemyShooter.Policy.Beta.sum": {
            "value": 0.00019925055999999968,
            "min": 0.00019925055999999968,
            "max": 0.008022459519999999,
            "count": 20
        },
        "EnemyShooter.Losses.CuriosityForwardLoss.mean": {
            "value": 3.1372009082559474e-07,
            "min": 3.1037788445012443e-07,
            "max": 0.19792075200507797,
            "count": 20
        },
        "EnemyShooter.Losses.CuriosityForwardLoss.sum": {
            "value": 3.1372009082559474e-07,
            "min": 3.1037788445012443e-07,
            "max": 0.19792075200507797,
            "count": 20
        },
        "EnemyShooter.Losses.CuriosityInverseLoss.mean": {
            "value": 1.1656579432033358,
            "min": 1.046839446261309,
            "max": 1.1751851286453736,
            "count": 20
        },
        "EnemyShooter.Losses.CuriosityInverseLoss.sum": {
            "value": 1.1656579432033358,
            "min": 1.046839446261309,
            "max": 1.1751851286453736,
            "count": 20
        },
        "AgentController2D.Losses.PolicyLoss.mean": {
            "value": 0.06291416784515605,
            "min": 0.05127555395786961,
            "max": 0.07644011368198941,
            "count": 56
        },
        "AgentController2D.Losses.PolicyLoss.sum": {
            "value": 0.06291416784515605,
            "min": 0.05127555395786961,
            "max": 0.07644011368198941,
            "count": 56
        },
        "AgentController2D.Losses.ValueLoss.mean": {
            "value": 0.0003098356913085354,
            "min": 5.254468997388055e-06,
            "max": 0.014267983925916876,
            "count": 56
        },
        "AgentController2D.Losses.ValueLoss.sum": {
            "value": 0.0003098356913085354,
            "min": 5.254468997388055e-06,
            "max": 0.014267983925916876,
            "count": 56
        },
        "AgentController2D.Policy.LearningRate.mean": {
            "value": 0.000133120073376,
            "min": 0.000133120073376,
            "max": 0.00041648001670399983,
            "count": 56
        },
        "AgentController2D.Policy.LearningRate.sum": {
            "value": 0.000133120073376,
            "min": 0.000133120073376,
            "max": 0.00041648001670399983,
            "count": 56
        },
        "AgentController2D.Policy.Epsilon.mean": {
            "value": 0.12662400000000004,
            "min": 0.12662400000000004,
            "max": 0.18329599999999996,
            "count": 56
        },
        "AgentController2D.Policy.Epsilon.sum": {
            "value": 0.12662400000000004,
            "min": 0.12662400000000004,
            "max": 0.18329599999999996,
            "count": 56
        },
        "AgentController2D.Policy.Beta.mean": {
            "value": 0.00014045760000000002,
            "min": 0.00014045760000000002,
            "max": 0.00041815040000000003,
            "count": 56
        },
        "AgentController2D.Policy.Beta.sum": {
            "value": 0.00014045760000000002,
            "min": 0.00014045760000000002,
            "max": 0.00041815040000000003,
            "count": 56
        },
        "AgentController2D.Losses.CuriosityForwardLoss.mean": {
            "value": 0.004404482618459345,
            "min": 9.302833712595178e-05,
            "max": 0.1376755590067963,
            "count": 56
        },
        "AgentController2D.Losses.CuriosityForwardLoss.sum": {
            "value": 0.004404482618459345,
            "min": 9.302833712595178e-05,
            "max": 0.1376755590067963,
            "count": 56
        },
        "AgentController2D.Losses.CuriosityInverseLoss.mean": {
            "value": 0.07315273598845427,
            "min": 0.00021778784963923196,
            "max": 1.099377862115701,
            "count": 56
        },
        "AgentController2D.Losses.CuriosityInverseLoss.sum": {
            "value": 0.07315273598845427,
            "min": 0.00021778784963923196,
            "max": 1.099377862115701,
            "count": 56
        },
        "PushAgent2D.Losses.PolicyLoss.mean": {
            "value": 0.04969693681807257,
            "min": 0.04492627769766841,
            "max": 0.052165684856590816,
            "count": 28
        },
        "PushAgent2D.Losses.PolicyLoss.sum": {
            "value": 0.04969693681807257,
            "min": 0.04492627769766841,
            "max": 0.052165684856590816,
            "count": 28
        },
        "PushAgent2D.Losses.ValueLoss.mean": {
            "value": 0.9559238972235471,
            "min": 0.008863247785484418,
            "max": 2.7868514508008957,
            "count": 28
        },
        "PushAgent2D.Losses.ValueLoss.sum": {
            "value": 0.9559238972235471,
            "min": 0.008863247785484418,
            "max": 2.7868514508008957,
            "count": 28
        },
        "PushAgent2D.Policy.LearningRate.mean": {
            "value": 0.0003781830243633999,
            "min": 0.0003781830243633999,
            "max": 0.0004704541725758334,
            "count": 28
        },
        "PushAgent2D.Policy.LearningRate.sum": {
            "value": 0.0003781830243633999,
            "min": 0.0003781830243633999,
            "max": 0.0004704541725758334,
            "count": 28
        },
        "PushAgent2D.Policy.Epsilon.mean": {
            "value": 0.17563659999999998,
            "min": 0.17563659999999998,
            "max": 0.19409083333333335,
            "count": 28
        },
        "PushAgent2D.Policy.Epsilon.sum": {
            "value": 0.17563659999999998,
            "min": 0.17563659999999998,
            "max": 0.19409083333333335,
            "count": 28
        },
        "PushAgent2D.Policy.Beta.mean": {
            "value": 0.00038061934000000006,
            "min": 0.00038061934000000006,
            "max": 0.0004710450833333333,
            "count": 28
        },
        "PushAgent2D.Policy.Beta.sum": {
            "value": 0.00038061934000000006,
            "min": 0.00038061934000000006,
            "max": 0.0004710450833333333,
            "count": 28
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1748078556",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "\\\\?\\C:\\Users\\MSII\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\mlagents-learn agents_config.yaml --run-id=pushjump --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.6.0+cu118",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1748111327"
    },
    "total": 32770.5789335,
    "count": 1,
    "self": 0.010623300004226621,
    "children": {
        "run_training.setup": {
            "total": 0.12844469999999975,
            "count": 1,
            "self": 0.12844469999999975
        },
        "TrainerController.start_learning": {
            "total": 32770.4398655,
            "count": 1,
            "self": 15.809635699082719,
            "children": {
                "TrainerController._reset_env": {
                    "total": 17.4954226,
                    "count": 1,
                    "self": 17.4954226
                },
                "TrainerController.advance": {
                    "total": 32736.864699700905,
                    "count": 581894,
                    "self": 19.09126530229696,
                    "children": {
                        "env_step": {
                            "total": 31298.73259449756,
                            "count": 581894,
                            "self": 26009.40231599606,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 5279.534850100491,
                                    "count": 581894,
                                    "self": 119.84434980048445,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 5159.6905003000065,
                                            "count": 1745637,
                                            "self": 5159.6905003000065
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 9.79542840100946,
                                    "count": 581893,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 32731.34328849965,
                                            "count": 581893,
                                            "is_parallel": true,
                                            "self": 7625.223538799757,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0034696000000007388,
                                                    "count": 3,
                                                    "is_parallel": true,
                                                    "self": 0.0009428999999983034,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0025267000000024353,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0025267000000024353
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 25106.116280099894,
                                                    "count": 581893,
                                                    "is_parallel": true,
                                                    "self": 81.90424669785352,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 74.1080986998002,
                                                            "count": 581893,
                                                            "is_parallel": true,
                                                            "self": 74.1080986998002
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 24623.776145600208,
                                                            "count": 581893,
                                                            "is_parallel": true,
                                                            "self": 24623.776145600208
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 326.32778910203376,
                                                            "count": 1745679,
                                                            "is_parallel": true,
                                                            "self": 180.68355100260942,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 145.64423809942434,
                                                                    "count": 4655144,
                                                                    "is_parallel": true,
                                                                    "self": 145.64423809942434
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1419.0408399010482,
                            "count": 1745679,
                            "self": 28.875787700027104,
                            "children": {
                                "process_trajectory": {
                                    "total": 510.5374661010383,
                                    "count": 1745679,
                                    "self": 505.847216701042,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 4.690249399996333,
                                            "count": 68,
                                            "self": 4.690249399996333
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 879.6275860999829,
                                    "count": 104,
                                    "self": 523.193131299852,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 356.4344548001309,
                                            "count": 34300,
                                            "self": 356.4344548001309
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.3000026228837669e-06,
                    "count": 1,
                    "self": 1.3000026228837669e-06
                },
                "TrainerController._save_models": {
                    "total": 0.27010620000510244,
                    "count": 1,
                    "self": 0.04721770001197001,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.22288849999313243,
                            "count": 3,
                            "self": 0.22288849999313243
                        }
                    }
                }
            }
        }
    }
}